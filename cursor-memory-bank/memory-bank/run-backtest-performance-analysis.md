# Детальный анализ производительности run_backtest

## Общая информация

- **Функция**: `BacktestExecutor::run_backtest`
- **Время относительно общего времени программы**: 4.84% (0.26% собственного времени, 4.58% с детьми)
- **Время относительно времени run_backtest**: 100% (базовая метрика)

## Анализ времени выполнения внутри run_backtest

### Распределение времени (относительно run_backtest = 100%)

1. **DynamicStrategy::evaluate**: 63.6% (3.08% от общего времени программы)
   - Это основное узкое место внутри run_backtest
   - Вызывается на каждой итерации цикла бэктеста
   
2. **evaluate_rule**: 16.3% (0.79% от общего времени программы)
   - Вызывается внутри evaluate для каждого правила
   - Множественные обращения к HashMap
   
3. **hash_one (хеширование)**: 14.5% (0.70% от общего времени программы)
   - Хеширование строк для доступа к HashMap
   - Хеширование TimeFrame
   - Хеширование TrendDirection
   
4. **process_decision**: 3.7% (0.18% от общего времени программы)
   - Обработка решений стратегии через PositionManager
   
5. **process_immediate_stop_checks**: 1.9% (0.09% от общего времени программы)
   - Проверка стоп-сигналов после открытия позиций
   
6. **Прочее**: ~0.0% (остальные операции)

## Детальный анализ узких мест

### 1. DynamicStrategy::evaluate (63.6% времени run_backtest)

**Проблемы**:
- Создает новый `Vec<Option<ConditionEvaluation>>` на каждой итерации
- Вызывает `evaluate_conditions` который обращается к HashMap через строковые ключи
- Обрабатывает все правила последовательно
- Создает новые HashMap для trend_weights в каждом правиле

**Код проблемы**:
```rust
fn evaluate(&self, context: &StrategyContext) -> Result<StrategyDecision, StrategyError> {
    let evaluations = self.evaluate_conditions(context)?;  // Создание Vec на каждой итерации
    // ...
    for rule in &self.entry_rules {
        let mut trend_weights = HashMap::new();  // Новый HashMap для каждого правила
        // ...
    }
}
```

**Влияние**: Критическое - это основное узкое место

### 2. evaluate_rule (16.3% времени run_backtest)

**Проблемы**:
- Множественные обращения к `evaluations.get(condition_id)` - хеширование строки на каждом обращении
- Создание HashMap для trend_weights на каждое правило
- Использование `.entry().or_insert()` для trend_weights - дополнительное хеширование

**Код проблемы**:
```rust
for condition_id in &rule.conditions {
    let evaluation = evaluations.get(condition_id)?;  // Хеширование строки каждый раз
    // ...
    let entry = trend_weights.entry(evaluation.trend).or_insert(0.0);  // Хеширование enum
    *entry += weight;
}
```

**Влияние**: Высокое - значительная часть времени

### 3. Хеширование (14.5% времени run_backtest)

**Проблемы**:
- Хеширование строк для доступа к HashMap (condition_id: String)
- Хеширование TimeFrame для доступа к `context.timeframe()`
- Хеширование TrendDirection для trend_weights

**Детали**:
- `core::hash::BuildHasher::hash_one`: 0.70% в контексте evaluate
- Дополнительные хеширования в других местах

**Влияние**: Высокое - значительная часть времени

### 4. process_decision (3.7% времени run_backtest)

**Проблемы**:
- Вызывается при каждом решении стратегии
- Внутри выполняет сложные операции с позициями

**Влияние**: Среднее - относительно небольшое, но может быть оптимизировано

### 5. process_immediate_stop_checks (1.9% времени run_backtest)

**Проблемы**:
- Вызывается после каждого открытия позиции
- Может вызываться в цикле (loop) если есть множественные стоп-сигналы

**Влияние**: Низкое - относительно небольшое время

## Предложения по оптимизации

### Приоритет 1: Критические оптимизации (ожидаемый эффект: 40-50% улучшение времени run_backtest)

#### 1.1. Замена HashMap на Vec для evaluations (критично)

**Проблема**: Использование `HashMap<String, ConditionEvaluation>` требует хеширования строки на каждом обращении.

**Решение**: Использовать `Vec<Option<ConditionEvaluation>>` с индексацией через `condition_lookup`.

**Ожидаемый эффект**: Снижение времени evaluate на 30-40%

**Код**:
```rust
// Вместо HashMap<String, ConditionEvaluation>
// Использовать Vec<Option<ConditionEvaluation>> с индексацией
let evaluation = &evaluations[self.condition_lookup[condition_id]];
```

**Сложность реализации**: Средняя (требует изменения структуры данных)

#### 1.2. Замена HashMap на массив для trend_weights (критично)

**Проблема**: Создание HashMap для trend_weights на каждое правило, хеширование TrendDirection.

**Решение**: Использовать массив фиксированного размера `[f32; 3]` для трех направлений.

**Ожидаемый эффект**: Снижение времени evaluate_rule на 20-30%

**Код**:
```rust
// Вместо HashMap<TrendDirection, f32>
let mut trend_weights = [0.0f32; 3];  // Up, Down, Sideways
match evaluation.trend {
    TrendDirection::Up => trend_weights[0] += weight,
    TrendDirection::Down => trend_weights[1] += weight,
    TrendDirection::Sideways => trend_weights[2] += weight,
}
```

**Сложность реализации**: Низкая (простая замена)

#### 1.3. Кэширование evaluations в StrategyContext

**Проблема**: `evaluate_conditions` создает новый Vec на каждой итерации, даже если условия не изменились.

**Решение**: Кэшировать evaluations в StrategyContext, инвалидировать только при изменении индекса timeframe.

**Ожидаемый эффект**: Снижение времени evaluate на 10-15%

**Сложность реализации**: Средняя (требует изменения StrategyContext)

### Приоритет 2: Важные оптимизации (ожидаемый эффект: 10-15% улучшение)

#### 2.1. Оптимизация доступа к TimeframeData

**Проблема**: Множественные вызовы `context.timeframe()` в одном evaluate, каждый раз хеширование TimeFrame.

**Решение**: Кэшировать ссылки на TimeframeData в локальных переменных в начале evaluate.

**Ожидаемый эффект**: Снижение времени на 3-5%

**Сложность реализации**: Низкая

#### 2.2. Batch обработка правил

**Проблема**: Обработка правил по одному, с повторными проверками условий.

**Решение**: Группировать правила по общим условиям, вычислять общие условия один раз.

**Ожидаемый эффект**: Снижение времени на 5-8%

**Сложность реализации**: Высокая (требует изменения логики)

#### 2.3. Оптимизация process_decision

**Проблема**: Вызывается при каждом решении, выполняет сложные операции.

**Решение**: Оптимизировать внутренние операции PositionManager, использовать кэширование где возможно.

**Ожидаемый эффект**: Снижение времени на 2-3%

**Сложность реализации**: Средняя

### Приоритет 3: Дополнительные оптимизации (ожидаемый эффект: 5-10% улучшение)

#### 3.1. Оптимизация аллокаций

**Проблема**: Множественные аллокации Vec и HashMap.

**Решение**: 
- Использовать `with_capacity` везде
- Переиспользовать буферы через `clear()` вместо создания новых
- Использовать arena allocator для временных структур

**Ожидаемый эффект**: Снижение времени на 3-5%

**Сложность реализации**: Средняя

#### 3.2. Ленивая инициализация условий

**Проблема**: Все условия вычисляются даже если они не используются в текущих правилах.

**Решение**: Вычислять условия только когда они нужны для правил, использовать dependency graph.

**Ожидаемый эффект**: Снижение времени на 5-10% (зависит от количества неиспользуемых условий)

**Сложность реализации**: Высокая

#### 3.3. Векторизация вычислений

**Проблема**: Последовательная обработка условий и правил.

**Решение**: Использовать SIMD для параллельной обработки числовых вычислений.

**Ожидаемый эффект**: Зависит от размера данных, потенциально 3-5%

**Сложность реализации**: Высокая

## План реализации и принятие решений

### Фаза 1: Быстрые победы (1-2 дня) - ПРИОРИТЕТ

**Задачи**:
1. ✅ Замена HashMap на массив для trend_weights
2. ✅ Замена HashMap на Vec для evaluations с индексацией
3. ✅ Кэширование ссылок на TimeframeData

**Ожидаемый результат**: 40-50% улучшение времени run_backtest

**Решение**: **РЕАЛИЗОВАТЬ СРАЗУ**

### Фаза 2: Средние оптимизации (3-5 дней)

**Задачи**:
1. Кэширование evaluations в StrategyContext
2. Оптимизация process_decision
3. Оптимизация аллокаций

**Ожидаемый результат**: Дополнительно 10-15% улучшение

**Решение**: **РЕАЛИЗОВАТЬ ПОСЛЕ ФАЗЫ 1**

### Фаза 3: Долгосрочные улучшения (1-2 недели)

**Задачи**:
1. Batch обработка правил
2. Ленивая инициализация условий
3. Векторизация вычислений

**Ожидаемый результат**: Дополнительно 5-10% улучшение

**Решение**: **ОЦЕНИТЬ ПОСЛЕ ФАЗЫ 2**

## Метрики для измерения

После каждой оптимизации необходимо измерять:
1. Время выполнения `run_backtest` на том же наборе данных
2. Количество аллокаций (через `dhat` или `heaptrack`)
3. Количество вызовов хеширования (через кастомный профилировщик)
4. Размер кэша попаданий (hit rate)

## Сравнение с общим временем программы

Важно понимать, что `run_backtest` занимает только 4.84% общего времени программы. Основное время (32.26%) уходит на:
- Подключение к ClickHouse (19.69%) - TLS инициализация
- Другие операции вне run_backtest

Однако оптимизация `run_backtest` критична, так как:
1. Это основная логика бэктеста
2. Выполняется в цикле на каждой итерации
3. Может быть вызвана многократно при оптимизации параметров

## Заключение

Основные узкие места в `run_backtest`:
1. **DynamicStrategy::evaluate** (63.6% времени run_backtest) - множественные HashMap операции
2. **Хеширование** (14.5% времени run_backtest) - строковые ключи и enum
3. **evaluate_rule** (16.3% времени run_backtest) - повторные обращения к HashMap

**Приоритетные оптимизации (Фаза 1) могут дать улучшение производительности на 40-50% времени run_backtest**, что при большом количестве итераций бэктеста будет очень значительным.

**Рекомендация**: Начать с Фазы 1 (быстрые победы) - замена HashMap на Vec/массивы и кэширование. Это даст максимальный эффект при минимальных затратах.

